import json
import re
import time
from typing import List, Dict, Any, Tuple

import requests
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from openai import OpenAI


# ===============================
# ìœ í‹¸
# ===============================
def strip_b_tags(text: str) -> str:
    """ë„¤ì´ë²„ ì§€ì—­ê²€ìƒ‰ ê²°ê³¼ titleì— ì„ì—¬ì˜¤ëŠ” <b> íƒœê·¸ ì œê±°"""
    if not text:
        return ""
    return re.sub(r"</?b>", "", text)


def get_secret_or_input(key: str, label: str, help_text: str = "", is_password: bool = True) -> str:
    """
    1) Streamlit Cloudì—ì„œëŠ” st.secretsë¥¼ ìš°ì„  ì‚¬ìš©
    2) ì—†ìœ¼ë©´ sidebar ì…ë ¥ìœ¼ë¡œ fallback
    """
    # st.secretsëŠ” ì¡´ì¬í•˜ì§€ë§Œ í‚¤ê°€ ì—†ì„ ìˆ˜ë„ ìˆìŒ
    if hasattr(st, "secrets") and key in st.secrets:
        return str(st.secrets[key])

    return st.sidebar.text_input(
        label,
        type="password" if is_password else "default",
        help=help_text,
    )


def naver_local_search(
    query: str,
    client_id: str,
    client_secret: str,
    display: int = 5,
    sort: str = "comment",
) -> List[Dict[str, str]]:
    """
    ë„¤ì´ë²„ ì§€ì—­ê²€ìƒ‰ APIë¡œ 'ì‹¤ì¡´' ì¥ì†Œ í›„ë³´ë¥¼ ê°€ì ¸ì˜¨ë‹¤.
    ë¬¸ì„œ: https://developers.naver.com/docs/serviceapi/search/local/local.md
    """
    url = "https://openapi.naver.com/v1/search/local.json"
    headers = {
        "X-Naver-Client-Id": client_id,
        "X-Naver-Client-Secret": client_secret,
    }
    params = {
        "query": query,
        "display": max(1, min(display, 5)),  # ë¬¸ì„œ ê¸°ì¤€ display ìµœëŒ€ê°€ ì‘ì€ í¸ì´ë¼ ì•ˆì „í•˜ê²Œ
        "start": 1,
        "sort": sort,  # comment | random ë“±
    }

    r = requests.get(url, headers=headers, params=params, timeout=10)
    r.raise_for_status()
    data = r.json()

    results: List[Dict[str, str]] = []
    for it in data.get("items", []):
        results.append(
            {
                "name": strip_b_tags(it.get("title", "")),
                "address": it.get("roadAddress") or it.get("address") or "",
                "category": it.get("category", ""),
                "tel": it.get("telephone", ""),
                "link": it.get("link", ""),
            }
        )
    return results


def dedupe_candidates(candidates: List[Dict[str, str]]) -> List[Dict[str, str]]:
    """ì´ë¦„+ì£¼ì†Œ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°"""
    seen = set()
    uniq = []
    for c in candidates:
        key = (c.get("name", "").strip(), c.get("address", "").strip())
        if key in seen:
            continue
        seen.add(key)
        uniq.append(c)
    return uniq


# ===============================
# Streamlit UI
# ===============================
st.set_page_config(page_title="LunchMate ğŸ±", layout="wide")
st.title("ğŸ½ï¸ LunchMate")
st.caption("ì§ì¥ì¸ì˜ ìƒí™©ê³¼ ì„ í˜¸ë„ë¥¼ ë¶„ì„í•´ ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì‹ë‹¹ í›„ë³´ ì¤‘ ìµœì ì˜ 3ê³³ì„ ì¶”ì²œí•©ë‹ˆë‹¤")

st.sidebar.header("ğŸ” API ì„¤ì •")

# âœ… ë°°í¬ ê¸°ì¤€: Secretsì— ë„£ëŠ” ê±¸ ì¶”ì²œ.
# - NAVER_CLIENT_ID
# - NAVER_CLIENT_SECRET
# - OPENAI_API_KEY (ì„ íƒ: ì…ë ¥ìœ¼ë¡œë„ ê°€ëŠ¥)
naver_client_id = get_secret_or_input(
    "NAVER_CLIENT_ID",
    "Naver Client ID",
    help_text="Streamlit Cloudë¼ë©´ Secretsì— NAVER_CLIENT_IDë¡œ ì €ì¥í•´ ë‘ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.",
)
naver_client_secret = get_secret_or_input(
    "NAVER_CLIENT_SECRET",
    "Naver Client Secret",
    help_text="Streamlit Cloudë¼ë©´ Secretsì— NAVER_CLIENT_SECRETë¡œ ì €ì¥í•´ ë‘ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.",
)
openai_api_key = get_secret_or_input(
    "OPENAI_API_KEY",
    "OpenAI API Key",
    help_text="Streamlit Cloudë¼ë©´ Secretsì— OPENAI_API_KEYë¡œ ì €ì¥í•´ ë‘ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.",
)

st.sidebar.header("ğŸ” ê²€ìƒ‰ ì¡°ê±´")
people = st.sidebar.slider("ì¸ì› ìˆ˜", 1, 10, 5)
distance = st.sidebar.selectbox("ì´ë™ ê±°ë¦¬", ["5ë¶„ ì´ë‚´", "10ë¶„ ì´ë‚´", "ìƒê´€ì—†ìŒ"])
food_type = st.sidebar.multiselect(
    "ìŒì‹ ì¢…ë¥˜",
    ["í•œì‹", "ì¤‘ì‹", "ì¼ì‹", "ì–‘ì‹", "ë¶„ì‹", "ê¸°íƒ€"],
    default=["í•œì‹"],
)

st.sidebar.caption(
    "âš ï¸ ë„¤ì´ë²„ ì§€ì—­ê²€ìƒ‰ APIë§Œìœ¼ë¡œëŠ” ë„ë³´ 5/10ë¶„ì„ ì •í™•íˆ ê³„ì‚°í•˜ê¸° ì–´ë ¤ìš¸ ìˆ˜ ìˆì–´ìš”.\n"
    "ì •í™•í•œ ì´ë™ì‹œê°„ í•„í„°ë§ì€ ì¶”í›„ Ncloud Maps Directions ì—°ë™ì„ ì¶”ì²œí•©ë‹ˆë‹¤."
)

st.subheader("ğŸ“ ì˜¤ëŠ˜ì˜ ìƒí™©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”")
situation = st.text_area(
    "ìì—°ìŠ¤ëŸ½ê²Œ ì…ë ¥í•´ ì£¼ì„¸ìš”",
    placeholder="ì˜ˆ: ì˜¤ëŠ˜ íŒ€ì¥ë‹˜ ëª¨ì‹œê³  5ëª…ì´ì„œ ì¡°ìš©íˆ 1ì‹œê°„ ë‚´ë¡œ ë¨¹ì–´ì•¼ í•´ìš”",
)

col1, col2, col3 = st.columns(3)
with col1:
    if st.button("âš¡ ë¹¨ë¦¬ ë¨¹ê¸°"):
        situation = "ì‹œê°„ì´ ì—†ì–´ì„œ ë¹¨ë¦¬ ë¨¹ì„ ìˆ˜ ìˆëŠ” ê³³ì„ ì°¾ê³  ìˆì–´ìš”"
with col2:
    if st.button("ğŸ‘¥ íŒ€ íšŒì‹"):
        situation = "íŒ€ì›ë“¤ê³¼ ì¡°ìš©íˆ ëŒ€í™”í•  ìˆ˜ ìˆëŠ” ì ì‹¬ íšŒì‹ ì¥ì†Œê°€ í•„ìš”í•´ìš”"
with col3:
    if st.button("ğŸ¥£ í•´ì¥ í•„ìš”"):
        situation = "ì–´ì œ ìˆ ì„ ë§ˆì…”ì„œ í•´ì¥ì— ì¢‹ì€ ìŒì‹ì„ ë¨¹ê³  ì‹¶ì–´ìš”"

st.write("")

# ===============================
# ì¶”ì²œ ë²„íŠ¼ í´ë¦­
# ===============================
if st.button("ğŸ¤– ì ì‹¬ ì¶”ì²œ ë°›ê¸°"):
    if not situation:
        st.warning("ìƒí™©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        st.stop()

    if not (naver_client_id and naver_client_secret):
        st.warning("ì‚¬ì´ë“œë°”ì— ë„¤ì´ë²„ Client ID / Secretì„ ì…ë ¥(ë˜ëŠ” Secrets ì„¤ì •)í•´ ì£¼ì„¸ìš”.")
        st.stop()

    if not openai_api_key:
        st.warning("ì‚¬ì´ë“œë°”ì— OpenAI API Keyë¥¼ ì…ë ¥(ë˜ëŠ” Secrets ì„¤ì •)í•´ ì£¼ì„¸ìš”.")
        st.stop()

    client = OpenAI(api_key=openai_api_key)

    # -------------------------------
    # 1) OpenAIë¡œ ê²€ìƒ‰ í‚¤ì›Œë“œ(ì¿¼ë¦¬) ì¶”ì¶œ
    # -------------------------------
    query_schema = {
        "name": "LunchQueries",
        "schema": {
            "type": "object",
            "additionalProperties": False,
            "properties": {
                "queries": {
                    "type": "array",
                    "minItems": 2,
                    "maxItems": 6,
                    "items": {"type": "string"},
                }
            },
            "required": ["queries"],
        },
    }

    system_query_prompt = (
        "ë„ˆëŠ” ë„¤ì´ë²„ ì§€ì—­ê²€ìƒ‰ APIì— ë„£ì„ 'ê²€ìƒ‰ í‚¤ì›Œë“œ'ë¥¼ ë§Œë“œëŠ” ë„ìš°ë¯¸ë‹¤.\n"
        "- ì ˆëŒ€ ì‹ë‹¹ ì´ë¦„ì„ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆë¼.\n"
        "- ì§§ê³  ê²€ìƒ‰ì— ì˜ ê±¸ë¦´ í‚¤ì›Œë“œë¡œë§Œ 2~6ê°œë¥¼ ì œì•ˆí•˜ë¼.\n"
        "- ì¶œë ¥ì€ JSONë§Œ."
    )

    user_query_prompt = (
        f"ìƒí™©: {situation}\n"
        f"ì¸ì›: {people}\n"
        f"ì´ë™ê±°ë¦¬ ì„ í˜¸: {distance}\n"
        f"ì„ í˜¸ ìŒì‹: {', '.join(food_type) if food_type else 'ìƒê´€ì—†ìŒ'}\n\n"
        "ë„¤ì´ë²„ ì§€ì—­ê²€ìƒ‰ì— ë„£ì„ ê²€ìƒ‰ì–´(queries) 2~6ê°œë¥¼ ë§Œë“¤ì–´ì¤˜.\n"
        "ì˜ˆ: 'ì¡°ìš©í•œ í•œì‹', 'ë£¸ ìˆëŠ” ì‹ë‹¹', 'ë¹ ë¥¸ ë°±ë°˜' ê°™ì€ í˜•íƒœ."
    )

    with st.spinner("ì¡°ê±´ì„ ë¶„ì„ ì¤‘..."):
        q_resp = client.responses.create(
            model="gpt-4.1-mini",
            input=[
                {"role": "system", "content": system_query_prompt},
                {"role": "user", "content": user_query_prompt},
            ],
            response_format={"type": "json_schema", "json_schema": query_schema},
        )

    queries = json.loads(q_resp.output_text).get("queries", [])
    if not queries:
        st.error("ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„±ì— ì‹¤íŒ¨í–ˆì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        st.stop()

    # -------------------------------
    # 2) ë„¤ì´ë²„ ì§€ì—­ê²€ìƒ‰ìœ¼ë¡œ 'ì‹¤ì¡´' í›„ë³´ ìˆ˜ì§‘
    # -------------------------------
    with st.spinner("ì£¼ë³€ ì‹¤ì œ ì‹ë‹¹ í›„ë³´ë¥¼ ì°¾ëŠ” ì¤‘..."):
        candidates: List[Dict[str, str]] = []
        for q in queries:
            try:
                candidates.extend(
                    naver_local_search(
                        query=q,
                        client_id=naver_client_id,
                        client_secret=naver_client_secret,
                        display=5,
                        sort="comment",
                    )
                )
                time.sleep(0.1)  # ë„ˆë¬´ ê³µê²©ì  í˜¸ì¶œ ë°©ì§€(ê°€ë²¼ìš´ í…œí¬ ì¡°ì ˆ)
            except requests.HTTPError as e:
                st.error(f"ë„¤ì´ë²„ ê²€ìƒ‰ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                st.stop()
            except requests.RequestException as e:
                st.error(f"ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e}")
                st.stop()

        candidates = dedupe_candidates(candidates)

    if not candidates:
        st.warning("ì¡°ê±´ì— ë§ëŠ” ì‹ë‹¹ í›„ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. í‚¤ì›Œë“œë¥¼ ë„“í˜€ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        st.stop()

    # -------------------------------
    # 3) OpenAIê°€ í›„ë³´ ì¤‘ì—ì„œë§Œ Top3 ì„ íƒ + ì´ìœ  ìƒì„±
    #    (ì¤‘ìš”: í›„ë³´ ë°– ì‹ë‹¹ ì¶”ì²œ ê¸ˆì§€)
    # -------------------------------
    rec_schema = {
        "name": "LunchRecommendations",
        "schema": {
            "type": "object",
            "additionalProperties": False,
            "properties": {
                "summary": {"type": "string"},
                "recommendations": {
                    "type": "array",
                    "minItems": 1,
                    "maxItems": 3,
                    "items": {
                        "type": "object",
                        "additionalProperties": False,
                        "properties": {
                            "rank": {"type": "integer"},
                            "name": {"type": "string"},
                            "reason": {"type": "string"},
                            "address": {"type": "string"},
                            "category": {"type": "string"},
                            "tel": {"type": "string"},
                            "link": {"type": "string"},
                        },
                        "required": ["rank", "name", "reason", "address", "category", "tel", "link"],
                    },
                },
            },
            "required": ["summary", "recommendations"],
        },
    }

    # í›„ë³´ë¥¼ ë„ˆë¬´ ë§ì´ ì£¼ë©´ ëª¨ë¸ì´ í—·ê°ˆë¦´ ìˆ˜ ìˆì–´ ê°€ê¹Œìš´ ê²ƒ ê¸°ì¤€ì´ ì—†ìœ¼ë‹ˆ ì¼ë‹¨ ìƒìœ„ Nê°œë¡œ ì œí•œ
    candidate_payload = candidates[:20]

    system_rec_prompt = (
        "ë„ˆëŠ” ì ì‹¬ ì¶”ì²œ íë ˆì´í„°ë‹¤.\n"
        "ë°˜ë“œì‹œ ì œê³µëœ candidates ëª©ë¡ì— ìˆëŠ” ì‹ë‹¹ë§Œ ì¶”ì²œí•  ìˆ˜ ìˆë‹¤.\n"
        "candidatesì— ì—†ëŠ” ì‹ë‹¹ ì´ë¦„ì„ ìƒˆë¡œ ë§Œë“¤ê±°ë‚˜ ì¶”ì²œí•˜ë©´ ì‹¤íŒ¨ë‹¤.\n"
        "ì‚¬ìš©ì ìƒí™©ê³¼ ì¡°ê±´ì— ë§ì¶° ìµœëŒ€ 3ê°œë¥¼ ê³ ë¥´ê³ , ì´ìœ ë¥¼ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•˜ë¼.\n"
        "ìˆ«ì(í‰ì /ê°€ê²©/ê±°ë¦¬/ì‹œê°„)ëŠ” ê·¼ê±° ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆë¼.\n"
        "ì¶œë ¥ì€ JSONë§Œ."
    )

    user_rec_prompt = json.dumps(
        {
            "situation": situation,
            "people": people,
            "distance_pref": distance,
            "food_type": food_type,
            "candidates": candidate_payload,
        },
        ensure_ascii=False,
    )

    with st.spinner("í›„ë³´ ì¤‘ì—ì„œ ìµœì ì˜ 3ê³³ì„ ê³ ë¥´ëŠ” ì¤‘..."):
        r_resp = client.responses.create(
            model="gpt-4.1-mini",
            input=[
                {"role": "system", "content": system_rec_prompt},
                {"role": "user", "content": user_rec_prompt},
            ],
            response_format={"type": "json_schema", "json_schema": rec_schema},
        )

    result = json.loads(r_resp.output_text)
    recommendations = result.get("recommendations", [])
    summary = result.get("summary", "ì¶”ì²œ ê²°ê³¼ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")

    if not recommendations:
        st.error("ì¶”ì²œ ê²°ê³¼ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        st.stop()

    # rank ì •ë ¬ ë³´ì •
    recommendations = sorted(recommendations, key=lambda x: x.get("rank", 999))

    # -------------------------------
    # ì¶œë ¥ UI
    # -------------------------------
    st.success(f"âœ… **{summary}**")

    st.subheader("ğŸ† ì¶”ì²œ ì‹ë‹¹ TOP (ì‹¤ì¡´ í›„ë³´ ê¸°ë°˜)")
    for r in recommendations:
        with st.container():
            st.markdown(f"### {r['rank']}ï¸âƒ£ {r['name']}")
            st.write(f"ğŸ“Œ ì¶”ì²œ ì´ìœ : {r['reason']}")
            st.write(f"ğŸ·ï¸ ì¹´í…Œê³ ë¦¬: {r.get('category','') or 'ì •ë³´ ì—†ìŒ'}")
            st.write(f"ğŸ“ ì£¼ì†Œ: {r.get('address','') or 'ì •ë³´ ì—†ìŒ'}")
            st.write(f"â˜ï¸ ì „í™”: {r.get('tel','') or 'ì •ë³´ ì—†ìŒ'}")
            if r.get("link"):
                st.markdown(f"ğŸ”— ë§í¬: {r['link']}")
            st.divider()

    # -------------------------------
    # ë¹„êµ(ê°„ë‹¨ í‘œ + ì°¨íŠ¸)
    # ë„¤ì´ë²„ APIëŠ” í‰ì  ìˆ˜ì¹˜ë¥¼ ì œê³µí•˜ì§€ ì•ŠëŠ” ê²½ìš°ê°€ ë§ì•„ì„œ, 'ì¹´í…Œê³ ë¦¬/ì „í™” ìœ ë¬´' ì •ë„ë§Œ ì‹œê°í™”
    # -------------------------------
    st.subheader("ğŸ“Š í›„ë³´ ë¹„êµ(ê¸°ë³¸ ì •ë³´)")
    df = pd.DataFrame(recommendations)
    st.dataframe(
        df[["rank", "name", "category", "address", "tel"]],
        use_container_width=True,
        hide_index=True,
    )

    # ì¹´í…Œê³ ë¦¬ ê¸¸ì´(ì •ë³´ëŸ‰) ê°™ì€ 'ì„ì‹œ ì§€í‘œ'ë¥¼ ì°¨íŠ¸ë¡œ. (ì›ì¹˜ ì•Šìœ¼ë©´ ì œê±° ê°€ëŠ¥)
    st.subheader("ğŸ“ˆ ì •ë³´ëŸ‰ ë¹„êµ(ì¹´í…Œê³ ë¦¬ í…ìŠ¤íŠ¸ ê¸¸ì´)")
    df["category_len"] = df["category"].fillna("").apply(len)

    fig, ax = plt.subplots()
    ax.bar(df["name"], df["category_len"])
    ax.set_ylabel("ì¹´í…Œê³ ë¦¬ í…ìŠ¤íŠ¸ ê¸¸ì´")
    st.pyplot(fig)

else:
    st.info("ğŸ‘† ìƒí™©ì„ ì…ë ¥í•˜ê³  **ì ì‹¬ ì¶”ì²œ ë°›ê¸°** ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
