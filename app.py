import json
import re
import time
from typing import List, Dict

import requests
import streamlit as st
import pandas as pd
from openai import OpenAI


# ===============================
# ìœ í‹¸
# ===============================
def strip_b_tags(text: str) -> str:
    if not text:
        return ""
    return re.sub(r"</?b>", "", text)


def get_secret(key: str) -> str:
    """Streamlit Cloud Secretsì—ì„œë§Œ ì½ê¸° (ì‚¬ì´ë“œë°” ì…ë ¥ ì œê±°)"""
    return str(st.secrets.get(key, "")).strip()


def naver_local_search(
    query: str,
    client_id: str,
    client_secret: str,
    display: int = 5,
    sort: str = "comment",
) -> List[Dict[str, str]]:
    """
    ë„¤ì´ë²„ ì§€ì—­ê²€ìƒ‰ APIë¡œ ì‹¤ì¡´ ì¥ì†Œ í›„ë³´ ìˆ˜ì§‘
    https://openapi.naver.com/v1/search/local.json
    """
    url = "https://openapi.naver.com/v1/search/local.json"
    headers = {
        "X-Naver-Client-Id": client_id,
        "X-Naver-Client-Secret": client_secret,
    }
    params = {
        "query": query,
        "display": max(1, min(display, 5)),
        "start": 1,
        "sort": sort,
    }
    r = requests.get(url, headers=headers, params=params, timeout=10)
    r.raise_for_status()
    data = r.json()

    results: List[Dict[str, str]] = []
    for it in data.get("items", []):
        results.append(
            {
                "name": strip_b_tags(it.get("title", "")),
                "address": it.get("roadAddress") or it.get("address") or "",
                "category": it.get("category", ""),
                "tel": it.get("telephone", ""),
                "link": it.get("link", ""),
            }
        )
    return results


def dedupe_candidates(candidates: List[Dict[str, str]]) -> List[Dict[str, str]]:
    seen = set()
    uniq = []
    for c in candidates:
        key = (c.get("name", "").strip(), c.get("address", "").strip())
        if key in seen:
            continue
        seen.add(key)
        uniq.append(c)
    return uniq


def extract_json_from_text(text: str) -> dict:
    """
    ëª¨ë¸ì´ JSON ì™¸ í…ìŠ¤íŠ¸ë¥¼ ì„ì—ˆì„ ë•Œë¥¼ ëŒ€ë¹„í•´,
    ê°€ì¥ ë°”ê¹¥ JSON ê°ì²´ë¥¼ ì°¾ì•„ íŒŒì‹± ì‹œë„.
    """
    text = text.strip()

    # ì´ë¯¸ JSONì´ë©´ ë°”ë¡œ
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        pass

    # ì½”ë“œë¸”ë¡ ì œê±°
    text = text.replace("```json", "```").replace("```", "")

    # ì²« { ë¶€í„° ë§ˆì§€ë§‰ } ê¹Œì§€ ì¶”ì¶œ
    start = text.find("{")
    end = text.rfind("}")
    if start == -1 or end == -1 or end <= start:
        raise json.JSONDecodeError("No JSON object found", text, 0)

    candidate = text[start : end + 1]
    return json.loads(candidate)


def llm_json(client: OpenAI, system: str, user: str, model: str = "gpt-4.1-mini", retries: int = 2) -> dict:
    """
    chat.completions ê¸°ë°˜ JSON ì‘ë‹µ ê°•ì œ.
    SDK í˜¸í™˜ì„±ì„ ìœ„í•´ response_format(json_schema) ëŒ€ì‹  í”„ë¡¬í”„íŠ¸ë¡œ ê°•ì œí•˜ê³ ,
    íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì§§ê²Œ ì¬ì‹œë„.
    """
    for attempt in range(retries + 1):
        resp = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": user},
            ],
            temperature=0.3,
        )
        text = resp.choices[0].message.content or ""
        try:
            return extract_json_from_text(text)
        except json.JSONDecodeError:
            if attempt == retries:
                raise
            # ì¬ì‹œë„: ë” ê°•í•˜ê²Œ â€œJSONë§Œâ€ ìš”êµ¬
            user = (
                user
                + "\n\në„ˆì˜ ì§ì „ ì¶œë ¥ì€ JSON íŒŒì‹±ì— ì‹¤íŒ¨í–ˆì–´. "
                  "ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ JSONë§Œ ë‹¤ì‹œ ì¶œë ¥í•´."
            )
    raise RuntimeError("Unreachable")


# ===============================
# Streamlit UI
# ===============================
st.set_page_config(page_title="LunchMate ğŸ±", layout="wide")
st.title("ğŸ½ï¸ LunchMate")
st.caption("ì§ì¥ì¸ì˜ ìƒí™©ê³¼ ì„ í˜¸ë„ë¥¼ ë¶„ì„í•´ â€˜ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”â€™ ì‹ë‹¹ í›„ë³´ ì¤‘ ìµœì ì˜ 3ê³³ì„ ì¶”ì²œí•©ë‹ˆë‹¤")

# Secrets ìƒíƒœ í‘œì‹œ(ì…ë ¥ì¹¸ ì—†ìŒ)
st.sidebar.header("ğŸ” ì—°ê²° ìƒíƒœ")
naver_client_id = get_secret("NAVER_CLIENT_ID")
naver_client_secret = get_secret("NAVER_CLIENT_SECRET")
openai_api_key = get_secret("OPENAI_API_KEY")

st.sidebar.write("ë„¤ì´ë²„ API:", "âœ…" if (naver_client_id and naver_client_secret) else "âŒ (Secrets í•„ìš”)")
st.sidebar.write("OpenAI API:", "âœ…" if openai_api_key else "âŒ (Secrets í•„ìš”)")
st.sidebar.caption("Streamlit Cloud â†’ Settings â†’ Secrets ì— í‚¤ë¥¼ ë„£ì–´ì•¼ í•©ë‹ˆë‹¤.")

st.sidebar.header("ğŸ” ê²€ìƒ‰ ì¡°ê±´")
people = st.sidebar.slider("ì¸ì› ìˆ˜", 1, 10, 5)
distance = st.sidebar.selectbox("ì´ë™ ê±°ë¦¬", ["5ë¶„ ì´ë‚´", "10ë¶„ ì´ë‚´", "ìƒê´€ì—†ìŒ"])
food_type = st.sidebar.multiselect(
    "ìŒì‹ ì¢…ë¥˜",
    ["í•œì‹", "ì¤‘ì‹", "ì¼ì‹", "ì–‘ì‹", "ë¶„ì‹", "ê¸°íƒ€"],
    default=["í•œì‹"],
)

st.subheader("ğŸ“ ì˜¤ëŠ˜ì˜ ìƒí™©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”")
situation = st.text_area(
    "ìì—°ìŠ¤ëŸ½ê²Œ ì…ë ¥í•´ ì£¼ì„¸ìš”",
    placeholder="ì˜ˆ: ì˜¤ëŠ˜ íŒ€ì¥ë‹˜ ëª¨ì‹œê³  5ëª…ì´ì„œ ì¡°ìš©íˆ 1ì‹œê°„ ë‚´ë¡œ ë¨¹ì–´ì•¼ í•´ìš”",
)

col1, col2, col3 = st.columns(3)
with col1:
    if st.button("âš¡ ë¹¨ë¦¬ ë¨¹ê¸°"):
        situation = "ì‹œê°„ì´ ì—†ì–´ì„œ ë¹¨ë¦¬ ë¨¹ì„ ìˆ˜ ìˆëŠ” ê³³ì„ ì°¾ê³  ìˆì–´ìš”"
with col2:
    if st.button("ğŸ‘¥ íŒ€ íšŒì‹"):
        situation = "íŒ€ì¥ë‹˜/íŒ€ì›ë“¤ê³¼ ì¡°ìš©íˆ ëŒ€í™”í•  ìˆ˜ ìˆëŠ” ì ì‹¬ íšŒì‹ ì¥ì†Œê°€ í•„ìš”í•´ìš”"
with col3:
    if st.button("ğŸ¥£ í•´ì¥ í•„ìš”"):
        situation = "ì–´ì œ ìˆ ì„ ë§ˆì…”ì„œ í•´ì¥ì— ì¢‹ì€ ìŒì‹ì„ ë¨¹ê³  ì‹¶ì–´ìš”"

st.write("")

# ===============================
# ì¶”ì²œ ë²„íŠ¼
# ===============================
if st.button("ğŸ¤– ì ì‹¬ ì¶”ì²œ ë°›ê¸°"):
    if not situation:
        st.warning("ìƒí™©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        st.stop()

    if not (naver_client_id and naver_client_secret):
        st.error("ë„¤ì´ë²„ Client ID/Secretì´ ì—†ìŠµë‹ˆë‹¤. Streamlit Cloudì˜ Secretsì— ë“±ë¡í•´ ì£¼ì„¸ìš”.")
        st.stop()

    if not openai_api_key:
        st.error("OpenAI API Keyê°€ ì—†ìŠµë‹ˆë‹¤. Streamlit Cloudì˜ Secretsì— OPENAI_API_KEYë¡œ ë“±ë¡í•´ ì£¼ì„¸ìš”.")
        st.stop()

    client = OpenAI(api_key=openai_api_key)

    # 1) OpenAIë¡œ 'ë„¤ì´ë²„ ì§€ì—­ê²€ìƒ‰ì— ë„£ì„ ê²€ìƒ‰ì–´' ìƒì„±
    system_query = (
        "ë„ˆëŠ” ë„¤ì´ë²„ ì§€ì—­ê²€ìƒ‰ APIì— ë„£ì„ 'ê²€ìƒ‰ì–´'ë¥¼ ìƒì„±í•˜ëŠ” ë„ìš°ë¯¸ë‹¤.\n"
        "- ì‹ë‹¹ ì´ë¦„ì„ ì ˆëŒ€ ë§Œë“¤ì§€ ë§ˆë¼.\n"
        "- ê²€ìƒ‰ì— ì˜ ê±¸ë¦´ ì§§ì€ í‚¤ì›Œë“œ ì¡°í•©ë§Œ ë§Œë“¤ì–´ë¼.\n"
        "- ì¶œë ¥ì€ JSONë§Œ. ìŠ¤í‚¤ë§ˆ:\n"
        "{ \"queries\": [\"...\", \"...\"] }\n"
        "- queriesëŠ” 2~6ê°œ."
    )
    user_query = (
        f"ìƒí™©: {situation}\n"
        f"ì¸ì›: {people}\n"
        f"ì´ë™ê±°ë¦¬ ì„ í˜¸: {distance}\n"
        f"ì„ í˜¸ ìŒì‹: {', '.join(food_type) if food_type else 'ìƒê´€ì—†ìŒ'}\n\n"
        "ë„¤ì´ë²„ ì§€ì—­ê²€ìƒ‰ì— ë„£ì„ queries 2~6ê°œë¥¼ ë§Œë“¤ì–´ì¤˜."
    )

    with st.spinner("ì¡°ê±´ì„ ë¶„ì„ ì¤‘..."):
        try:
            q_data = llm_json(client, system_query, user_query)
            queries = q_data.get("queries", [])
        except Exception:
            st.error("ê²€ìƒ‰ì–´ ìƒì„±ì— ì‹¤íŒ¨í–ˆì–´ìš”. (OpenAI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨)")
            st.stop()

    queries = [q.strip() for q in queries if isinstance(q, str) and q.strip()]
    if not queries:
        st.warning("ê²€ìƒ‰ì–´ë¥¼ ë§Œë“¤ì§€ ëª»í–ˆì–´ìš”. ì…ë ¥ì„ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì ì–´ì£¼ì„¸ìš”.")
        st.stop()

    # 2) ë„¤ì´ë²„ ì§€ì—­ê²€ìƒ‰ìœ¼ë¡œ 'ì‹¤ì¡´ í›„ë³´' ìˆ˜ì§‘
    with st.spinner("ì£¼ë³€ ì‹¤ì œ ì‹ë‹¹ í›„ë³´ë¥¼ ì°¾ëŠ” ì¤‘..."):
        candidates: List[Dict[str, str]] = []
        for q in queries[:6]:
            try:
                candidates.extend(
                    naver_local_search(
                        query=q,
                        client_id=naver_client_id,
                        client_secret=naver_client_secret,
                        display=5,
                        sort="comment",
                    )
                )
                time.sleep(0.08)
            except requests.HTTPError as e:
                st.error(f"ë„¤ì´ë²„ ì§€ì—­ê²€ìƒ‰ API í˜¸ì¶œ ì‹¤íŒ¨(HTTP): {e}")
                st.stop()
            except requests.RequestException as e:
                st.error(f"ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e}")
                st.stop()

        candidates = dedupe_candidates(candidates)

    if not candidates:
        st.warning("ì¡°ê±´ì— ë§ëŠ” ì‹¤ì œ ì‹ë‹¹ í›„ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. í‚¤ì›Œë“œë¥¼ ë„“í˜€ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        st.stop()

    # 3) í›„ë³´ ì•ˆì—ì„œë§Œ TOP3 ì¶”ì²œ + ì´ìœ  ìƒì„± (í›„ë³´ ë°– ê¸ˆì§€)
    system_rec = (
        "ë„ˆëŠ” ì ì‹¬ ì¶”ì²œ íë ˆì´í„°ë‹¤.\n"
        "- ë°˜ë“œì‹œ candidates ëª©ë¡ì— ìˆëŠ” ì‹ë‹¹ë§Œ ì¶”ì²œí•  ìˆ˜ ìˆë‹¤.\n"
        "- candidatesì— ì—†ëŠ” ì‹ë‹¹ì„ ìƒˆë¡œ ë§Œë“¤ë©´ ì‹¤íŒ¨ë‹¤.\n"
        "- ìˆ«ì(í‰ì /ê°€ê²©/ê±°ë¦¬/ì‹œê°„)ëŠ” ê·¼ê±° ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆë¼.\n"
        "- ì¶œë ¥ì€ JSONë§Œ. ìŠ¤í‚¤ë§ˆ:\n"
        "{\n"
        "  \"summary\": \"í•œ ì¤„ ê²°ë¡ \",\n"
        "  \"recommendations\": [\n"
        "    {\"rank\": 1, \"name\": \"...\", \"reason\": \"...\", \"address\": \"...\", \"category\": \"...\", \"tel\": \"...\", \"link\": \"...\"}\n"
        "  ]\n"
        "}\n"
        "- recommendationsëŠ” 1~3ê°œ, rankëŠ” 1ë¶€í„°."
    )

    payload = {
        "situation": situation,
        "people": people,
        "distance_pref": distance,
        "food_type": food_type,
        "candidates": candidates[:25],  # ë„ˆë¬´ ê¸¸ë©´ í˜¼ë€ -> ì œí•œ
    }
    user_rec = json.dumps(payload, ensure_ascii=False)

    with st.spinner("í›„ë³´ ì¤‘ì—ì„œ ìµœì ì˜ 3ê³³ì„ ê³ ë¥´ëŠ” ì¤‘..."):
        try:
            r_data = llm_json(client, system_rec, user_rec)
        except Exception:
            st.error("ì¶”ì²œ ê²°ê³¼ ìƒì„±ì— ì‹¤íŒ¨í–ˆì–´ìš”. (OpenAI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨)")
            st.stop()

    summary = r_data.get("summary", "ì¶”ì²œ ê²°ê³¼ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    recommendations = r_data.get("recommendations", [])

    if not isinstance(recommendations, list) or len(recommendations) == 0:
        st.error("ì¶”ì²œ ê²°ê³¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        st.stop()

    # ì •ë ¬ ë° ìµœëŒ€ 3ê°œë¡œ ê°•ì œ
    recommendations = [r for r in recommendations if isinstance(r, dict)]
    recommendations = sorted(recommendations, key=lambda x: int(x.get("rank", 999)))
    recommendations = recommendations[:3]

    # UI ì¶œë ¥
    st.success(f"âœ… **{summary}**")

    st.subheader("ğŸ† ì¶”ì²œ ì‹ë‹¹ TOP 3 (ë„¤ì´ë²„ í›„ë³´ ê¸°ë°˜)")
    for r in recommendations:
        with st.container():
            st.markdown(f"### {r.get('rank', '')}ï¸âƒ£ {r.get('name', 'ì´ë¦„ ì—†ìŒ')}")
            st.write(f"ğŸ“Œ ì¶”ì²œ ì´ìœ : {r.get('reason', '')}")
            st.write(f"ğŸ·ï¸ ì¹´í…Œê³ ë¦¬: {r.get('category', '') or 'ì •ë³´ ì—†ìŒ'}")
            st.write(f"ğŸ“ ì£¼ì†Œ: {r.get('address', '') or 'ì •ë³´ ì—†ìŒ'}")
            st.write(f"â˜ï¸ ì „í™”: {r.get('tel', '') or 'ì •ë³´ ì—†ìŒ'}")
            if r.get("link"):
                st.markdown(f"ğŸ”— ë§í¬: {r['link']}")
            st.divider()

    st.subheader("ğŸ“‹ ë¹„êµ í‘œ")
    df = pd.DataFrame(recommendations)
    cols = [c for c in ["rank", "name", "category", "address", "tel", "link"] if c in df.columns]
    st.dataframe(df[cols], use_container_width=True, hide_index=True)

    # ê°„ë‹¨ ì°¨íŠ¸(â€œì¹´í…Œê³ ë¦¬ ì •ë³´ëŸ‰â€ì²˜ëŸ¼ ê²€ì¦ ê°€ëŠ¥í•œ ê°’ë§Œ)
    st.subheader("ğŸ“ˆ ì •ë³´ëŸ‰ ë¹„êµ(ì¹´í…Œê³ ë¦¬ ê¸€ììˆ˜)")
    df["category_len"] = df.get("category", "").fillna("").astype(str).apply(len)
    st.bar_chart(df.set_index("name")["category_len"])

else:
    st.info("ğŸ‘† ìƒí™©ì„ ì…ë ¥í•˜ê³  **ì ì‹¬ ì¶”ì²œ ë°›ê¸°** ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
